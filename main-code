# Import the necessary libraries and modules
import torch
import transformers


# Define the ChatBot class
class ChatBot:
    def __init__(self, tokenizer, model):
        # Initialize the tokenizer and model attributes
        self.tokenizer = tokenizer
        self.model = model

    def generate_response(self, input_text):
        # Tokenize the input text and add the special tokens
        input_ids = self.tokenizer.encode(input_text, return_tensors='pt')
        # Convert the eos_token_id to a tensor and concatenate it with the input ids
        input_ids = torch.cat([input_ids, torch.tensor(self.tokenizer.eos_token_id)], dim=-1)

        # Generate a response using the model
        output_ids = self.model.generate(input_ids, max_length=50)

        # Decode the output ids and remove the special tokens
        output_text = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)

        # Return the output text
        return output_text

# Initialize the tokenizer and model using a pre-trained GPT-2 model
tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')
model = transformers.GPT2LMHeadModel.from_pretrained('gpt2')

# Create an instance of the ChatBot class
chatbot = ChatBot(tokenizer, model)

# Start the main loop
while True:
    # Get the user input
    user_input = input('User: ')

    # Check if the user wants to quit
    if user_input.lower() == 'quit':
        break

    # Generate a response using the chatbot
    response = chatbot.generate_response(user_input)

    # Print the response
    print('ChatBot: ' + response)
